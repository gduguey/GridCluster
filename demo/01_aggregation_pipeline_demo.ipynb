{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the spatial and temporal aggregation pipeline.  \n",
    "It walks through each step: building the fine network, optionally constructing a coarse network, \n",
    "computing node features, generating distance matrices, applying clustering, and producing \n",
    "aggregated datasets.  \n",
    "\n",
    "**Purpose**: Show how to run the full pipeline as well as inspect each component step-by-step.  \n",
    "**Inputs**: Raw data under `/DATA/raw/` (downloaded from Google Drive, see [README.md](../README.md) for details.) \n",
    "**Outputs**: Aggregated datasets and cached metrics under `/DATA/processed/`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path().cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Quick start: run the full pipeline once\n",
    "\n",
    "This cell shows the *shortest possible* way to run the aggregation pipeline end-to-end.\n",
    "\n",
    "You choose a granularity (`\"fine\"` → ~385 nodes, or `\"coarse\"` → 17 zones derived from the fine network), set a year, and provide simple weights and hyperparameters. The call:\n",
    "\n",
    "- builds the selected network,\n",
    "- computes features,\n",
    "- performs spatial aggregation (to `n_representative_nodes`),\n",
    "- performs temporal aggregation (to `k_representative_days`), and\n",
    "- returns results plus a **version hash** (which is used to create versioned folders on disk in `results/joint_aggregation_results/v<hash>/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\src\\aggregation\\utils.py:140: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  counties.geometry.centroid.y,\n",
      "c:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\src\\aggregation\\utils.py:141: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  counties.geometry.centroid.x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached metrics loaded from C:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\results\\distance_metrics\\v202586c2.\n",
      "Results saved to C:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\results\\joint_aggregation_results\\v4b02ae39\n",
      "Results saved under version: 4b02ae39\n",
      "Representative day weights: {11: 11, 37: 14, 40: 22, 47: 48, 48: 68, 53: 9, 185: 37, 199: 26, 202: 25, 218: 42, 232: 43, 248: 20}\n",
      "Version hash: 4b02ae39\n",
      "Available result blocks: ['spatiotemporal', 'temporal_only', 'original', 'clusters']\n"
     ]
    }
   ],
   "source": [
    "from src.aggregation.pipeline import StaticPreprocessor, DynamicProcessor\n",
    "\n",
    "# --- Step 1. Static preprocessing ---\n",
    "# Choose \"fine\" (385 nodes) or \"coarse\" (17 zones)\n",
    "preproc = StaticPreprocessor(granularity=\"coarse\", year=2013).preprocess()\n",
    "\n",
    "# --- Step 2. Dynamic run with hyperparameters ---\n",
    "dyn = DynamicProcessor(preprocessor=preproc)\n",
    "\n",
    "weights={\n",
    "        'position': 1.0,\n",
    "        'time_series': 0.8,\n",
    "        'duration_curves': 1.2,\n",
    "        'ramp_duration_curves': 1.0,\n",
    "        'intra_correlation': 1.0,\n",
    "        'inter_correlation': 1.0\n",
    "    }\n",
    "\n",
    "results, version_hash, day_weights, metadata = dyn.run_with_hyperparameters(\n",
    "    weights=weights,\n",
    "    n_representative_nodes=10,\n",
    "    k_representative_days=12\n",
    ")\n",
    "\n",
    "print(\"Results saved under version:\", version_hash)\n",
    "print(\"Representative day weights:\", day_weights)\n",
    "\n",
    "print(\"Version hash:\", version_hash)\n",
    "print(\"Available result blocks:\", list(results.keys()))  # ['spatiotemporal', 'temporal_only', 'original', 'clusters']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Component details\n",
    "### Configure the aggregation run\n",
    "\n",
    "We first instantiate a `Config` that controls data year, network granularity (choose `\"fine\"` ~385 nodes or `\"coarse\"` 17 zones), and which features to compute.  \n",
    "Running `config.help()` prints a short overview of all knobs and how they affect the pipeline.  \n",
    "The same `Config` object will be reused when building networks, computing features, distances, and saving results. \n",
    "\n",
    "The full structure of `Config` (both preprocessing and hyperparameters) is detailed in [src/aggregation/README.md](../src/aggregation/README.md). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Overview:\n",
      "\n",
      "1. Data Preproc (Immutable):\n",
      "   Contains data processing parameters. Key attributes:\n",
      "   - year (int): The data year (2007-2013).\n",
      "   - granularity (str): Data granularity; allowed: 'coarse', 'fine'.\n",
      "   - active_features (list): Features to include; allowed: 'position', 'time_series', 'duration_curves',\n",
      "      'ramp_duration_curves', 'intra_correlation'.\n",
      "2. Model Hyper (Mutable):\n",
      "   Contains model configuration parameters. Key attributes:\n",
      "   - n_representative_nodes (int): Number of representative nodes.\n",
      "   - k_representative_days (int): Number of representative days (1–365).\n",
      "   - inter_correlation (bool): Whether inter-node correlation is included.\n",
      "   - kmed_seed (int): Seed for KMedoids (0 means no seed).\n",
      "   - kmed_n_init (int): Number of KMedoids initializations.\n",
      "   - weights (dict): Weights for various features. Can be manually set or auto-generated based on \n",
      "      data_preproc.active_features and model_hyper.inter_correlation\n",
      "\n",
      "3. Path (Immutable):\n",
      "   Contains dynamically generated paths based on data_preproc.year, including:\n",
      "   - demand_file, wind_cf_file, solar_cf_file, and others.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.aggregation.settings import Config\n",
    "\n",
    "config = Config(\n",
    "    year=2013,\n",
    "    granularity=\"coarse\",\n",
    "    active_features=['position', 'time_series', 'duration_curves', 'ramp_duration_curves', 'intra_correlation']\n",
    ")\n",
    "\n",
    "# Display configuration help.\n",
    "config.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the fine network\n",
    "\n",
    "This cell shows how to explicitly build the **fine network** (≈385 nodes) and inspect the raw time-series shapes:\n",
    "\n",
    "- `FineNetwork(config)` loads and cleans **wind/solar** capacity factors and **demand**.\n",
    "- `.build_fine_ntw()` returns a dict with:\n",
    "    - `'nodes'`: a DataFrame with `Lat`, `Lon`\n",
    "    - `'time_series'`: a dict with three DataFrames (`'wind'`, `'solar'`, `'demand'`), each of shape **T × N** (rows = hours, columns = nodes).\n",
    "\n",
    "We also show how to access **population & county** utilities (via `utils`) indirectly through the network builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\src\\aggregation\\utils.py:140: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  counties.geometry.centroid.y,\n",
      "c:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\src\\aggregation\\utils.py:141: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  counties.geometry.centroid.x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes columns: ['Lat', 'Lon']\n",
      "wind: shape (8760, 385)\n",
      "solar: shape (8760, 385)\n",
      "demand: shape (8760, 385)\n"
     ]
    }
   ],
   "source": [
    "from src.aggregation.utils import FineNetwork\n",
    "\n",
    "cfg = Config(\n",
    "    year=2013,\n",
    "    granularity=\"fine\",\n",
    "    active_features=[\"position\", \"time_series\", \"duration_curves\", \"ramp_duration_curves\", \"intra_correlation\"],\n",
    ")\n",
    "\n",
    "fine_builder = FineNetwork(cfg)\n",
    "fine_data = fine_builder.build_fine_ntw()\n",
    "\n",
    "print(\"Nodes columns:\", fine_data[\"nodes\"].columns.tolist())\n",
    "for k, df in fine_data[\"time_series\"].items():\n",
    "    print(f\"{k}: shape {df.shape}\")  # (hours, nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing coarse network (17 zones) vs staying fine\n",
    "\n",
    "To build a **coarse network (17 zones)**, we:\n",
    "\n",
    "- build the fine network first,\n",
    "- snap each fine node to the nearest coarse zone center (provided by `coarse_node_file` in `settings.PathConfig`), and\n",
    "- **medoid** the wind/solar time series per zone (demand is **summed**).\n",
    "\n",
    "The coarse network has the same structure as the fine one, but with **17** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\src\\aggregation\\utils.py:140: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  counties.geometry.centroid.y,\n",
      "c:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\src\\aggregation\\utils.py:141: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  counties.geometry.centroid.x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse nodes: 17\n",
      "wind: shape (8760, 17)\n",
      "solar: shape (8760, 17)\n",
      "demand: shape (8760, 17)\n"
     ]
    }
   ],
   "source": [
    "from src.aggregation.utils import CoarseNetwork\n",
    "\n",
    "cfg_coarse = Config(\n",
    "    year=2013,\n",
    "    granularity=\"coarse\",\n",
    "    active_features=[\"position\", \"time_series\", \"duration_curves\", \"ramp_duration_curves\", \"intra_correlation\"],\n",
    ")\n",
    "\n",
    "fine_builder = FineNetwork(cfg_coarse)\n",
    "fine_data = fine_builder.build_fine_ntw()\n",
    "\n",
    "coarse_builder = CoarseNetwork(cfg_coarse, fine_data)\n",
    "coarse_data = coarse_builder.build_coarse_ntw()\n",
    "\n",
    "print(\"Coarse nodes:\", coarse_data[\"nodes\"].shape[0])\n",
    "for k, df in coarse_data[\"time_series\"].items():\n",
    "    print(f\"{k}: shape {df.shape}\")  # time series now have 17 columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the `Network` object and inspecting features\n",
    "\n",
    "`Network` bundles **nodes + time series** and computes **features** for each node based on `active_features`:\n",
    "\n",
    "- `'position'`: `(Lat, Lon)` tuple per node\n",
    "- `'time_series'`: dict `{ 'wind': 1D array, 'solar': 1D array, 'demand': 1D array }` per node\n",
    "- `'duration_curves'`: per-series sorted values (normalized [0,1])\n",
    "- `'ramp_duration_curves'`: per-series sorted absolute hour-to-hour ramps (normalized [0,1])\n",
    "- `'intra_correlation'`: per-node pairwise correlations between series types within the node (intra)\n",
    "\n",
    "You can also subset dates via `start_day`/`end_day` (e.g., `\"06-01\"` to `\"08-31\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature keys at node 0: ['position', 'time_series', 'duration_curves', 'ramp_duration_curves', 'intra_correlation']\n",
      "Position: (42.642711, -70.865107)\n",
      "Time-series keys: ['wind', 'solar', 'demand']\n",
      "Duration-curves keys: ['wind', 'solar', 'demand']\n",
      "Ramp-duration-curves keys: ['wind', 'solar', 'demand']\n",
      "Intra-correlation keys: [('wind', 'solar'), ('wind', 'demand'), ('solar', 'demand')]\n"
     ]
    }
   ],
   "source": [
    "from src.aggregation.utils import Network\n",
    "\n",
    "ntw = Network(\n",
    "    nodes_df=coarse_data[\"nodes\"],\n",
    "    time_series=coarse_data[\"time_series\"],\n",
    "    config=cfg_coarse,                 # uses active_features from Config\n",
    "    start_day=None, end_day=None\n",
    ")\n",
    "\n",
    "# Inspect features for the first node (index 0)\n",
    "f0 = ntw.features[0]\n",
    "print(\"Feature keys at node 0:\", list(f0.keys()))\n",
    "print(\"Position:\", f0[\"position\"])\n",
    "print(\"Time-series keys:\", list(f0[\"time_series\"].keys()))\n",
    "print(\"Duration-curves keys:\", list(f0[\"duration_curves\"].keys()))\n",
    "print(\"Ramp-duration-curves keys:\", list(f0[\"ramp_duration_curves\"].keys()))\n",
    "print(\"Intra-correlation keys:\", list(f0[\"intra_correlation\"].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance metrics and caching\n",
    "\n",
    "`SpatialAggregation.DistanceCalculator.compute_metrics(...)` builds a **distance matrix per feature** (e.g., `'position'`, `'time_series'`, `'intra_correlation'`), then **normalizes** each to [0,1].\n",
    "\n",
    "The `SpatialAggregation` object **caches** these metrics on disk:\n",
    "\n",
    "- Folder: `results/distance_metrics/v<hash>/`\n",
    "- Files:\n",
    "    - `metrics.npz` — NumPy archive with one array per metric key\n",
    "    - `metadata.json` — configuration (immutable preproc & `inter_correlation`) used to compute the hash\n",
    "\n",
    "When you request `aggregation.distance_metrics` again with the same config, it loads from cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached metrics loaded from C:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\results\\distance_metrics\\v202586c2.\n",
      "Cached feature keys: ['position', 'time_series', 'ramp_duration_curves', 'duration_curves', 'intra_correlation', 'inter_correlation']\n",
      "Cache root: C:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\results\\distance_metrics\n",
      "Versioned cache folder: C:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\results\\distance_metrics\\v202586c2\n"
     ]
    }
   ],
   "source": [
    "from src.aggregation.models import SpatialAggregation\n",
    "\n",
    "# Build aggregation object from features\n",
    "agg = SpatialAggregation(node_features=ntw.features, config=cfg_coarse)\n",
    "\n",
    "# First access → compute & save\n",
    "dm = agg.distance_metrics\n",
    "print(\"Cached feature keys:\", list(dm.features.keys()))\n",
    "\n",
    "# Inspect the cache folder\n",
    "cache_root = cfg.path.distance_metrics\n",
    "print(\"Cache root:\", cache_root)\n",
    "# The exact versioned folder:\n",
    "versioned = agg._io.get_metrics_path()\n",
    "print(\"Versioned cache folder:\", versioned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial aggregation (k-medoids or MIP)\n",
    "\n",
    "We combine the normalized distance metrics using **weights** from `Config.model_hyper.weights`.  \n",
    "\n",
    "Two methods are available:\n",
    "\n",
    "- **k-medoids** (`Clusterer`) — a fast heuristic that runs multiple random initializations.  \n",
    "  - `Config.model_hyper.n_init`: number of random restarts (higher = more robust, slower).  \n",
    "  - `Config.model_hyper.seed`: RNG seed for reproducibility (42 for my thesis).  \n",
    "\n",
    "- **Optimization** (`Optimizer` with Gurobi) — solves a facility-location–like MILP to select medoids exactly.  \n",
    "\n",
    "**Shared hyperparameters for both methods:**  \n",
    "- `Config.model_hyper.weights`: vector of feature weights for distance computation.  \n",
    "- `Config.model_hyper.n_representative`: number of medoids (clusters) to select.  \n",
    "\n",
    "**Outputs (same for both methods):**  \n",
    "- `clusters`: dictionary mapping medoid → list of assigned members  \n",
    "  (e.g. `{5: [5, 17, 22], 11: [11, 2, 9], ...}`)  \n",
    "- `representatives`: list of medoid indices (e.g. `[5, 11, 34, ...]`)\n",
    "\n",
    "The pipeline runs this automatically, but here we show a **manual** call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-medoids representatives: [1, 2, 7, 11, 16]\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 307 rows, 306 columns and 884 nonzeros\n",
      "Model fingerprint: 0xd68da009\n",
      "Variable types: 0 continuous, 306 integer (306 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [4e-01, 8e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+00]\n",
      "Presolve time: 0.00s\n",
      "Presolved: 307 rows, 306 columns, 884 nonzeros\n",
      "Variable types: 0 continuous, 306 integer (306 binary)\n",
      "Found heuristic solution: objective 6.0508429\n",
      "\n",
      "Root relaxation: objective 5.098466e+00, 90 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    5.09847    0   20    6.05084    5.09847  15.7%     -    0s\n",
      "H    0     0                       5.7178631    5.09847  10.8%     -    0s\n",
      "H    0     0                       5.6825532    5.09847  10.3%     -    0s\n",
      "H    0     0                       5.2855766    5.09847  3.54%     -    0s\n",
      "H    0     0                       5.1266169    5.09847  0.55%     -    0s\n",
      "H    0     0                       5.1260938    5.09847  0.54%     -    0s\n",
      "H    0     0                       5.1208341    5.09847  0.44%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  Zero half: 2\n",
      "\n",
      "Explored 1 nodes (90 simplex iterations) in 0.04 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 7: 5.12083 5.12609 5.12662 ... 6.05084\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.120834096244e+00, best bound 5.120834096244e+00, gap 0.0000%\n",
      "Optimization representatives: [2, 5, 7, 12, 16]\n"
     ]
    }
   ],
   "source": [
    "# Manually combine metrics and run k-medoids\n",
    "weights = cfg_coarse.model_hyper.weights  # auto-generated from active_features (+ inter_correlation)\n",
    "total = SpatialAggregation._combine_metrics(dm, weights)\n",
    "\n",
    "# Option A: k-medoids\n",
    "kmed = SpatialAggregation.Clusterer(cfg_coarse)\n",
    "k = cfg_coarse.model_hyper.n_representative_nodes\n",
    "res_km = kmed.cluster(total, k=k)\n",
    "print(\"K-medoids representatives:\", res_km[\"representatives\"])\n",
    "\n",
    "# Option B: exact optimization\n",
    "opt = SpatialAggregation.Optimizer(cfg_coarse)\n",
    "res_opt = opt.solve(total)\n",
    "print(\"Optimization representatives:\", res_opt[\"representatives\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal aggregation (representative days)\n",
    "\n",
    "Given spatial clusters, `TemporalAggregation`:\n",
    "\n",
    "- samples/normalizes the time series of clustered nodes,\n",
    "- builds a **day-by-feature matrix**, and\n",
    "- clusters into **`k_representative_days`** using k-medoids (distance: Euclidean between day vectors).\n",
    "\n",
    "It returns clusters of days and their representatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representative days: [2, 47, 48, 53, 177, 185, 199, 211, 218, 236]\n",
      "#Clusters (days): 10\n"
     ]
    }
   ],
   "source": [
    "from src.aggregation.models import TemporalAggregation\n",
    "\n",
    "spatial_results = res_km  # or res_opt\n",
    "temp = TemporalAggregation(cfg_coarse, ntw.features, spatial_results)\n",
    "temporal_results = temp.aggregate()\n",
    "\n",
    "print(\"Representative days:\", sorted(temporal_results[\"representatives\"]))\n",
    "print(\"#Clusters (days):\", len(temporal_results[\"clusters\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving complete aggregation results\n",
    "\n",
    "`Results(...)` packages **three blocks** and saves them to disk under a versioned folder based on both **preproc** and **hyperparams**:\n",
    "\n",
    "- Folder: `results/joint_aggregation_results/v<hash>/`\n",
    "- Saved:\n",
    "    - `spatiotemporal/` — aggregated nodes/branches + rep-day time series (CSVs)\n",
    "    - `temporal_only/` — original nodes/branches + rep-day time series (CSVs)\n",
    "    - `original/` — original nodes/branches + full time series (CSVs)\n",
    "    - `clustering/` — JSONs for spatial & temporal clusters\n",
    "    - `metadata.json` — config (preproc + hyperparameters, including weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\results\\joint_aggregation_results\\vc3e25595\n",
      "Saved blocks: ['spatiotemporal', 'temporal_only', 'original', 'clusters']\n",
      "Base path: C:\\Users\\g630d\\Documents\\00_Academic\\2024-2025_MIT\\Research\\2024 09 Thesis\\Code\\results\\joint_aggregation_results\n"
     ]
    }
   ],
   "source": [
    "from src.aggregation.utils import Results\n",
    "\n",
    "results_obj = Results(\n",
    "    config=cfg,\n",
    "    data=fine_data,                     # original (fine) network data\n",
    "    spatial_agg_results=spatial_results,\n",
    "    temporal_agg_results=temporal_results,\n",
    "    auto_save=True\n",
    ")\n",
    "\n",
    "print(\"Saved blocks:\", list(results_obj.results.keys()))\n",
    "print(\"Base path:\", cfg.path.joint_aggregation_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
