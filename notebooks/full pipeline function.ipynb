{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path().cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.settings import Config\n",
    "from src.utils import Network, Results, FineNetwork, CoarseNetwork\n",
    "from src.models import SpatialAggregation, TemporalAggregation\n",
    "from src.visualization import Visualizer\n",
    "from Full_GTEP_Solve.modules_v2 import read_data, GTEP\n",
    "\n",
    "import pickle\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from functools import lru_cache\n",
    "from dataclasses import asdict\n",
    "import hashlib\n",
    "import json\n",
    "from numba import njit, prange\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    year=2013,\n",
    "    cf_k_neighbors=1,\n",
    "    demand_decay_alpha=0.4,\n",
    "    granularity=\"high_bis\",\n",
    "    active_features=['position', 'time_series', 'duration_curves', 'ramp_duration_curves', 'intra_correlation']\n",
    ")\n",
    "\n",
    "# # Display configuration help.\n",
    "# config.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\g630d\\Documents\\00_Cours\\2024-2025_MIT\\00 Thesis\\dev\\src\\utils.py:143: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  counties.geometry.centroid.y,\n",
      "c:\\Users\\g630d\\Documents\\00_Cours\\2024-2025_MIT\\00 Thesis\\dev\\src\\utils.py:144: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  counties.geometry.centroid.x\n"
     ]
    }
   ],
   "source": [
    "Fine_NTW = FineNetwork(config)\n",
    "fine_ntw = Fine_NTW.build_fine_ntw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coarse_NTW = CoarseNetwork(config, fine_ntw)\n",
    "coarse_ntw = Coarse_NTW.build_coarse_ntw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntw = Network(fine_ntw[\"nodes\"], fine_ntw[\"time_series\"], config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = SpatialAggregation(ntw.features, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing distance metrics for 385 nodes. This might take a while...\n",
      "Computing position distance...\n",
      "position distance computed in 0:00:01.903200.\n",
      "Computing time_series distance...\n",
      "time_series distance computed in 0:00:01.920175.\n",
      "Computing ramp_duration_curves distance...\n",
      "ramp_duration_curves distance computed in 0:00:01.000139.\n",
      "Computing duration_curves distance...\n",
      "duration_curves distance computed in 0:00:01.066451.\n",
      "Computing intra_correlation distance...\n",
      "intra_correlation distance computed in 0:00:00.\n",
      "Computing inter_correlation distance...\n",
      "inter_correlation distance computed in 0:00:52.478903.\n",
      "All distance metrics computed.\n",
      "Starting normalization...\n",
      "Normalization completed in 0:00:00.\n",
      "Total computation time: 0:00:58.369377.\n",
      "Saving metrics...\n",
      "Metrics saved to c:\\Users\\g630d\\Documents\\00_Cours\\2024-2025_MIT\\00 Thesis\\dev\\results\\distance_metrics\\v11d728cf.\n"
     ]
    }
   ],
   "source": [
    "distances = spatial.distance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_dict = spatial.aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = TemporalAggregation(config, ntw.features, assignment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_days = temp.aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to c:\\Users\\g630d\\Documents\\00_Cours\\2024-2025_MIT\\00 Thesis\\dev\\results\\joint_aggregation_results\\v6efb3e6a\n"
     ]
    }
   ],
   "source": [
    "results = Results(config, fine_ntw, assignment_dict, rep_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import hashlib\n",
    "import json\n",
    "from dataclasses import asdict\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "class StaticPreprocessor:\n",
    "    \"\"\"Handles network construction and feature preparation that doesn't change with hyperparameters\"\"\"\n",
    "    def __init__(self, granularity: str, year: int = 2013, active_features: list = ['position', 'time_series', 'duration_curves', 'ramp_duration_curves', 'intra_correlation'], inter_correlation: bool = True):\n",
    "        self.config = Config(\n",
    "            year=year,\n",
    "            granularity=granularity,\n",
    "            active_features=active_features,\n",
    "        )\n",
    "        self.config.model_hyper.inter_correlation = inter_correlation\n",
    "\n",
    "        self.network_data = None\n",
    "        self.fine_data = None\n",
    "        self.ntw = None\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"Run all static preprocessing steps\"\"\"\n",
    "        # Build network based on granularity\n",
    "        config = self.config\n",
    "        if self.config.data_preproc.granularity == \"coarse\":\n",
    "            fine_builder = FineNetwork(config)\n",
    "            self.fine_data = fine_builder.build_fine_ntw()\n",
    "            coarse_builder = CoarseNetwork(config, self.fine_data)\n",
    "            self.network_data = coarse_builder.build_coarse_ntw()\n",
    "        elif self.config.data_preproc.granularity == \"fine\":\n",
    "            fine_builder = FineNetwork(config)\n",
    "            self.fine_data = fine_builder.build_fine_ntw()\n",
    "            self.network_data = self.fine_data\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported granularity. Use 'fine' or 'coarse'.\")\n",
    "        \n",
    "        self.ntw = Network(\n",
    "            self.network_data[\"nodes\"],\n",
    "            self.network_data[\"time_series\"],\n",
    "            config\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "class DynamicProcessor:\n",
    "    \"\"\"Handles parameter-dependent operations that can vary during grid search\"\"\"\n",
    "    def __init__(self, preprocessor: StaticPreprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.base_config = preprocessor.config\n",
    "        self.ntw = preprocessor.ntw\n",
    "\n",
    "    def run_with_hyperparameters(self, \n",
    "                               weights: dict,\n",
    "                               n_representative_nodes: int,\n",
    "                               k_representative_days: int) -> tuple[dict, str]:\n",
    "        \"\"\"Execute parameter-dependent pipeline steps\"\"\"\n",
    "        ntw = self.ntw\n",
    "        if ntw is None:\n",
    "            raise ValueError(\"Network data not initialized. Run static preprocessing first.\")\n",
    "        \n",
    "        # Update config with current hyperparameters\n",
    "        current_config = self.base_config\n",
    "        current_config.model_hyper.weights = weights\n",
    "        current_config.model_hyper.n_representative_nodes = n_representative_nodes\n",
    "        current_config.model_hyper.k_representative_days = k_representative_days\n",
    "\n",
    "        # Spatial aggregation\n",
    "        spatial_agg = SpatialAggregation(ntw.features, current_config)\n",
    "        spatial_results = spatial_agg.aggregate()\n",
    "\n",
    "        # Temporal aggregation\n",
    "        temporal_agg = TemporalAggregation(current_config, ntw.features, spatial_results)\n",
    "        temporal_results = temporal_agg.aggregate()\n",
    "\n",
    "        # Process and save results\n",
    "        results = Results(current_config, self.preprocessor.network_data, spatial_results, temporal_results)\n",
    "        \n",
    "        return results.results, self._get_result_hash(current_config)\n",
    "\n",
    "    def _get_result_hash(self, config: Config) -> str:\n",
    "        \"\"\"Generate unique hash for current configuration\"\"\"\n",
    "        config_dict = {\n",
    "            \"data_preproc\" : asdict(config.data_preproc),\n",
    "            \"model_hyper\": config.model_hyper.__dict__\n",
    "        }\n",
    "        version_hash = hashlib.md5(json.dumps(config_dict, sort_keys=True).encode()).hexdigest()[:8]   \n",
    "        return version_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\g630d\\Documents\\00_Cours\\2024-2025_MIT\\00 Thesis\\dev\\src\\utils.py:143: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  counties.geometry.centroid.y,\n",
      "c:\\Users\\g630d\\Documents\\00_Cours\\2024-2025_MIT\\00 Thesis\\dev\\src\\utils.py:144: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  counties.geometry.centroid.x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing distance metrics for 385 nodes. This might take a while...\n",
      "Computing position distance...\n",
      "position distance computed in 0:00:01.038343.\n",
      "Computing time_series distance...\n",
      "time_series distance computed in 0:00:02.813008.\n",
      "Computing ramp_duration_curves distance...\n",
      "ramp_duration_curves distance computed in 0:00:02.180739.\n",
      "Computing duration_curves distance...\n",
      "duration_curves distance computed in 0:00:02.343365.\n",
      "Computing intra_correlation distance...\n",
      "intra_correlation distance computed in 0:00:00.011087.\n",
      "Computing inter_correlation distance...\n",
      "inter_correlation distance computed in 0:00:56.406467.\n",
      "All distance metrics computed.\n",
      "Starting normalization...\n",
      "Normalization completed in 0:00:00.017601.\n",
      "Total computation time: 0:01:04.810610.\n",
      "Saving metrics...\n",
      "Metrics saved to c:\\Users\\g630d\\Documents\\00_Cours\\2024-2025_MIT\\00 Thesis\\dev\\results\\distance_metrics\\v6cdfff21.\n",
      "Results saved to c:\\Users\\g630d\\Documents\\00_Cours\\2024-2025_MIT\\00 Thesis\\dev\\results\\joint_aggregation_results\\v85c39199\n"
     ]
    }
   ],
   "source": [
    "# Static preprocessing (run once)\n",
    "static_prep = StaticPreprocessor(granularity=\"fine\").preprocess()\n",
    "\n",
    "# Dynamic processor (reused for multiple runs)\n",
    "processor = DynamicProcessor(static_prep)\n",
    "\n",
    "res, version_hash = processor.run_with_hyperparameters(\n",
    "    weights={\n",
    "        'position': 1.0,\n",
    "        'time_series': 0.8,\n",
    "        'duration_curves': 1.2,\n",
    "        'ramp_duration_curves': 1.0,\n",
    "        'intra_correlation': 1.0,\n",
    "        'inter_correlation': 1.0\n",
    "    },\n",
    "    n_representative_nodes=10,\n",
    "    k_representative_days=15\n",
    ")\n",
    "\n",
    "# # Define parameter grid\n",
    "# param_grid = {\n",
    "#     'weights': [\n",
    "#         {'position': 1.0, 'time_series': 0.8, 'duration_curves': 1.2},\n",
    "#         {'position': 0.8, 'time_series': 1.0, 'duration_curves': 1.0}\n",
    "#     ],\n",
    "#     'n_representative_nodes': [10, 15],\n",
    "#     'k_representative_days': [8, 10]\n",
    "# }\n",
    "\n",
    "# # Execute grid search\n",
    "# results = {}\n",
    "# for params in ParameterGrid(param_grid):\n",
    "#     res, version_hash = processor.run_with_hyperparameters(\n",
    "#         weights=params['weights'],\n",
    "#         n_representative_nodes=params['n_representative_nodes'],\n",
    "#         k_representative_days=params['k_representative_days']\n",
    "#     )\n",
    "#     results[version_hash] = {'params': params, 'results': res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'91c16280'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version_hash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
